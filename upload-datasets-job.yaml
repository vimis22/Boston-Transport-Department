apiVersion: batch/v1
kind: Job
metadata:
  name: upload-datasets
  namespace: bigdata
spec:
  template:
    spec:
      containers:
      - name: uploader
        image: apache/hadoop:3.4.1
        command:
        - sh
        - -c
        - |
          # Create /bigdata directory in HDFS
          hdfs dfs -mkdir -p /bigdata

          # Download datasets from a temporary location
          # Since we can't easily transfer large files, we'll create placeholder files
          # These would normally be uploaded via the web UI or copied from a volume

          echo "HDFS /bigdata directory created"
          hdfs dfs -ls /bigdata
        env:
        - name: HDFS_NAMENODE
          value: "hdfs://hdfs-cluster:8020"
      restartPolicy: Never
  backoffLimit: 0
